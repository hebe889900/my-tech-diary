## greenlet &ã€€gevent

### [Understanding greenlet](http://www.slideshare.net/saghul/understanding-greenlet)

#### What is greenlet

* Micro-threads with **no implicit scheduling**
* Lightweight coroutines
* Cooperative(switching)
* Only one can run at a time(concurrency, not parallelism)

#### API

* `grentlet.greenlet(func, parent=None)`
* `greenlet.switch(*args, **kw)` switch to `func`. The first `switch` will call `func(*args, **kw)`
* `greenlet.throw([type, [value, [tb]]])` switch then raise

```python
import greenlet

main = greenlet.getcurrent()  # the main greenlet

def foo(n):  # [1], forward back to main, so main will have return value 42
  main.switch(n)  # switch control to main

def bar(n):  # Note: here will be context for g1
  foo(n)  # [1], forward to foo
  return 'Hello'  # [2], g1 dies here, go back to main

g1.greenlet.greenlet(bar)  # create a greenlet
print g1.switch(42)  # 42 [1]
print g1.switch()  # 'Hello' [2]
print g1.dead  # True
```

#### Structure

* Each greenlet has a parent
* When a greenlet dies, control will be switched to its parent
  * Kinda like GOTO....
* Stack slices are copied from the heap, use registers to save and restore context

#### continulet

* PyPy has a native implementation of greenlet, built on top of continulet
* continulet = one shot continuation
* API
  * `continulet(func, *args, *kw)`: create a continulet which will call `func(*args, **kw)`(unlike greenlet which will create that context with `switch` later on and call it when `switch` executes for the first time)
  * `continulet.switch(value=None, to=None)`: start or activate
  * `continulet.throw(type, value=None, tb=None, to=None)`: switch then raise, but raise after switching is done

### [Greenlet Vs. Threads](http://stackoverflow.com/questions/15556718/greenlet-vs-threads)

> Greenlets provide concurrency but not parallelism.
> * Concurrency is when code can run independently of other code.
> * Parallelism is the execution of concurrent code simultaneously.
> * Parallelism is particularly useful when there's a lot of work to be done in userspace, and that's typically CPU-heavy stuff.
> * Concurrency is useful for breaking apart problems, enabling different parts to be scheduled and managed more easily in parallel.

### [How do I Gevent?](http://blog.hownowstephen.com/post/50743415449/gevent-tutorial)

#### What are gevent good for

* Greenlets are not the silver bullet. It can't get you pass around GIL when you do CPU-intensive tasks.
* Gevent monkey patches `os`, `select`, `socket`, `ssl`, `thread` and `time`, so if you spend a lot of time waiting on them, gevent will be good for ya!
  * Use `python -m cProfile my_gevent_candidate_program.py` to determine if it is really what you need
  * Warning: some libraries can be screwed up because of this monkey patching, so be careful!

#### How it works

* Gevent has a promise-like system, but it's nearly invisible most of the time, thanks to the monkey patching.
* The scheduler is very performant when switching contexts.
* When one of the greenlets needs to block on I/O, it sends the job to libevent, then yields control to the scheduler for it to switch contexts

#### Getting started

* How to monkey patch the standard library:

  ```python
  import gevent.monkey
  gevent.monkey.patch_all()
  ```
* Use `gevent.joinall(greenlets)` to wait for a list of greenlets.

#### Pooling

* You can create one greenlet per I/O task since greenlets are cheap, but you still need to consider the limits of other resources(like the network). So it's better to create a pool(`gevent.pool.Pool()`) of greenlets.

  ```python
  pool = gevent.pool.Pool(num_of_workers)
  pool.full()  # check if the pool is full
  pool.spawn(crawler, link)  # spawn with available workers
  pool.join()  # wait for everything to complete
  ```
* Pool spawning is blocking. When you call `pool.spawn`, gevent will check if the pool is full, and **wait for availability** if it isn't -- this could cause **dining philosipher** problems when greentlets calls `pool.spawn` at the same time.

#### Queuing

* Use `gevent.queue.Queue()`, replace `pool.spawn` calls with queuing operations(put the arguments into the queue, not the greenlets into the pool)

  ```python
  queue = gevent.queue.Queue()
  queue.put(link)
  try:
    url = queue.get(timeout=1)
  except gevent.queue.Empty
    break
  ```
  Then you spawn `num_of_workers` workers in the pool, and let them consume arguments in the queue. Then use `pool.join()` to wait for them to complete(i.e. the queue is empty).
* The final pattern

  ```python
  queue.put(link)
  pool.spawn(crawler)

  while not queue.empty() and not pool.free_count() == 5:
      gevent.sleep(0.1)
      for x in xrange(0, min(queue.qsize(), pool.free_count())):
          pool.spawn(crawler)
  ```

## Tricks

### Avoid the cache

Always forget about this...just `ctrl+F5`.

### Optimize callbacks

Saw this interesting code in underscore.js

```javascript
var optimizeCb = function(func, context, argCount) {
  if (context === void 0) return func;
  switch (argCount == null ? 3 : argCount) {
    case 1: return function(value) {
      return func.call(context, value);
    };
    case 2: return function(value, other) {
      return func.call(context, value, other);
    };
    case 3: return function(value, index, collection) {
      return func.call(context, value, index, collection);
    };
    case 4: return function(accumulator, value, index, collection) {
      return func.call(context, accumulator, value, index, collection);
    };
  }
  return function() {
    return func.apply(context, arguments);
  };
};
```

`arguments` tends to wreck optimizations in JS engines, so they try to avoid it when the number of arguments is small(although this requires manually passing the argument count). They also apply a convention for arguments with it.